{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, Sequential, regularizers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import interp\n",
    "\n",
    "import math\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from evaluation import compute_performance_measures\n",
    "\n",
    "from utils import *\n",
    "from layers import *\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  #按需分配显存\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# tf.random.set_seed(111111)\n",
    "# np.random.seed(111111)\n",
    "# random.seed(111111)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, name='MHACapsNet'):\n",
    "\n",
    "    x = Conv2D(16, 5, 1, kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = MaxPool2D(2)(x)\n",
    "    #x = AvgPool2D(2)(x)\n",
    "    \n",
    "    x = Conv2D(32, 5, 1, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = MaxPool2D(2)(x)\n",
    "    #x = AvgPool2D(2)(x)\n",
    "    \n",
    "    x = Conv2D(64, 5, 2, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(128, 5, 1, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = PrimaryCaps(256, 128, 9, 32, 8)(x)\n",
    "    \n",
    "    if name == 'MHACapsNet':   \n",
    "        digit_caps = MHACaps(3, 16, 4)(x)\n",
    "        digit_caps_len = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(digit_caps)\n",
    "        model = Model(inputs=[inputs], outputs=[digit_caps_len], name=name)\n",
    "\n",
    "    if name == 'CapsNet':\n",
    "        x = Reshape((1, 1, 32, 8))(x)\n",
    "        digit_caps = DigitCaps(3, 16, 3)(x)  \n",
    "        digit_caps_len = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(digit_caps)\n",
    "        model = Model(inputs=[inputs], outputs=[digit_caps_len], name=name)\n",
    "        \n",
    "    if name == 'ARCapsNet':\n",
    "        x = Reshape((1, 1, 32, 8))(x)\n",
    "        digit_caps = ARCaps(3, 16)(x)  \n",
    "        digit_caps_len = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(digit_caps)\n",
    "        model = Model(inputs=[inputs], outputs=[digit_caps_len], name=name)\n",
    "    \n",
    "#     if name == 'FCC': \n",
    "#         x = Reshape((1, 1, 32, 8))(x)\n",
    "#         digit_caps = DigitCaps(3, 16, None)(x) \n",
    "#         digit_caps_len = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(digit_caps)\n",
    "#         model = Model(inputs=[inputs], outputs=[digit_caps_len], name=name)\n",
    "        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e05297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128, 128, 3))\n",
    "model = create_model(inputs)\n",
    "adam = optimizers.Adam(learning_rate=0.0001)     \n",
    "model.compile(loss=margin_loss, optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f771ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.totaltime = time.time()\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.totaltime = time.time() - self.totaltime\n",
    "        \n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning decay rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5 \n",
    "    epochs_drop = 20  \n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2febc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  \n",
    "num_classes = 3\n",
    "epochs = 100\n",
    "\n",
    "images= np.load(\"data/image.npy\")\n",
    "labels= np.load(\"data/label.npy\")\n",
    "\n",
    "# images= np.load(\"newData/image.npy\")\n",
    "# labels= np.load(\"newData/label.npy\")\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480663aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    "cvscores = []\n",
    "cvpre = []\n",
    "cvrecall  =[]\n",
    "cvf1 = []\n",
    "cvauc = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold.split(images, labels)):\n",
    "    \n",
    "    path = \"model-cv/cv\"+str(k+1)+\"/\"\n",
    "    \n",
    "    x_train = images[train]\n",
    "    x_test = images[test]\n",
    "    y_train = labels[train]\n",
    "    y_test = labels[test]\n",
    "    \n",
    "    np.save(path + 'data/x_train.npy', x_train)\n",
    "    np.save(path + 'data/y_train.npy', y_train)\n",
    "    np.save(path + 'data/x_test.npy', x_test)\n",
    "    np.save(path + 'data/y_test.npy', y_test)\n",
    "    \n",
    "    #class weights to handle class imbalance\n",
    "    class_weights = {0: 1-np.count_nonzero(y_train==0)/len(y_train), \n",
    "                     1: 1-np.count_nonzero(y_train==1)/len(y_train), \n",
    "                     2: 1-np.count_nonzero(y_train==2)/len(y_train)}\n",
    "\n",
    "    # 将整型标签转为onehot\n",
    "    y_train = utils.to_categorical(y_train, num_classes)\n",
    "    y_test = utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    \n",
    "    # The best model is selected based on the accuracy on the validation set\n",
    "    filepath = path+\"weights-best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    # learning schedule callback\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    callbacks_list = [checkpoint, lrate, time_callback]\n",
    "\n",
    "    inputs = Input(shape=(128, 128, 3))\n",
    "    #===================================Model======================================\n",
    "    model = create_model(inputs, name=\"MHACapsNet\")\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=0.001)     \n",
    "    model.compile(loss=margin_loss, optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    print(\"========================= 第\"+ str(k+1) +\"折开始 ============================\")\n",
    "    history = model.fit(x_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=2,\n",
    "                    #validation_split=0.1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    class_weight=class_weights, \n",
    "                    shuffle=True, \n",
    "                    callbacks=callbacks_list)\n",
    "    \n",
    "    np.save(path+'acc.npy', history.history['accuracy'])\n",
    "    np.save(path+'val_acc.npy', history.history['val_accuracy'])\n",
    "    np.save(path+'loss.npy', history.history['loss'])\n",
    "    np.save(path+'val_loss.npy', history.history['val_loss'])\n",
    "    \n",
    "    model.load_weights(filepath)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    predict = model.predict([x_test])\n",
    "    \n",
    "    # ===================auc=========================\n",
    "    n_classes = y_test.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predict[:, i], )\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    roc_auc[\"macro\"] = roc_auc_score(y_test, predict, multi_class=\"ovo\", average=\"macro\")\n",
    "    roc_auc[\"weighted\"] = roc_auc_score(y_test, predict, multi_class=\"ovo\", average=\"weighted\")\n",
    "    # ===================================================\n",
    "\n",
    "    y_pre = np.argmax(predict, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    report = classification_report(y_test, y_pre, output_dict=True)\n",
    "    df1 = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    df1['auc'] = [roc_auc[0], roc_auc[1], roc_auc[2], \" \", roc_auc[\"macro\"], roc_auc[\"weighted\"]]\n",
    "    \n",
    "    # Write it into csv format\n",
    "    df1.to_csv(path+'report.csv', index=True, header=True)\n",
    "    \n",
    "    cvpre.append(df1.loc['macro avg','precision'] * 100)\n",
    "    cvrecall.append(df1.loc['macro avg','recall'] * 100)\n",
    "    cvf1.append(df1.loc['macro avg','f1-score'] * 100)\n",
    "    cvauc.append(df1.loc['macro avg','auc'] * 100)\n",
    "    \n",
    "    data = confusion_matrix(y_test, y_pre)\n",
    "    names = ['normal', 'pneumonia', 'COVID-19']\n",
    "    df_cm = pd.DataFrame(data, columns=names, index=names)\n",
    "    df_cm.to_csv(path+'cm.csv', index=True, header=True)\n",
    "    print(\"========================= 第\"+ str(k+1) +\"折结束 ============================\")\n",
    "    \n",
    "print(\"accuracy：%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"precision：%.2f%% (+/- %.2f%%)\" % (np.mean(cvpre), np.std(cvpre)))\n",
    "print(\"recall：%.2f%% (+/- %.2f%%)\" % (np.mean(cvrecall), np.std(cvrecall)))\n",
    "print(\"f1-score：%.2f%% (+/- %.2f%%)\" % (np.mean(cvf1), np.std(cvf1)))\n",
    "print(\"auc：%.2f%% (+/- %.2f%%)\" % (np.mean(cvauc), np.std(cvauc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f166ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(time_callback.times)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4141b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2417d6f1",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0516d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= './model-cv/best1/cv1/'\n",
    "path2 = './model-cv/best1/cv2/'\n",
    "path3 = './model-cv/best1/cv3/'\n",
    "path4 = './model-cv/best1/cv4/'\n",
    "path5 = './model-cv/best1/cv5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(path5 + 'weights-best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa15df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(path5 + 'data/x_test.npy')\n",
    "y_test = np.load(path5 + 'data/y_test.npy')\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "predict = model.predict([x_test])\n",
    "    \n",
    "# ===================auc=========================\n",
    "n_classes = y_test.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predict[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "roc_auc[\"macro\"] = roc_auc_score(y_test, predict, multi_class=\"ovo\", average=\"macro\")\n",
    "roc_auc[\"weighted\"] = roc_auc_score(y_test, predict, multi_class=\"ovo\", average=\"weighted\")\n",
    "# ===================================================\n",
    "\n",
    "y_pre = np.argmax(predict, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_test, y_pre, output_dict=True)\n",
    "df1 = pd.DataFrame(report).transpose()\n",
    "\n",
    "df1['auc'] = [roc_auc[0], roc_auc[1], roc_auc[2], \" \", roc_auc[\"macro\"], roc_auc[\"weighted\"]]\n",
    "\n",
    "# Write it into csv format\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461251ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6)) \n",
    "color=['r','r','r']\n",
    "a = y_test[y_pre!=y_test]\n",
    "for i,(img, p) in enumerate(zip(x_test[y_pre!=y_test], predict[y_pre!=y_test])):\n",
    "    ax1=plt.subplot(2,4,i+1)\n",
    "    ax1.imshow(img)\n",
    "    #ax.set_title(\"label = %d\"%label)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([]) \n",
    "    ax2=plt.subplot(2,4,i+5)\n",
    "    color[a[i]] = 'b'\n",
    "    ax2.bar(x=['Normal','Pneumonia','Covid-19'],height=p,width=0.5,color=color)\n",
    "    #ax.set_title(\"label = %d\"%label)\n",
    "    ax2.set_xticklabels(['Normal','Pneumonia','Covid-19'],\n",
    "                        rotation = 30,#fontsize = 'large',\n",
    "                        fontdict={'fontsize': 13})\n",
    "    plt.yticks(fontsize=13)\n",
    "    color=['r','r','r']\n",
    "plt.tight_layout() \n",
    "plt.savefig('./model-cv/fig/failure.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6)) \n",
    "color=['r','r','r']\n",
    "a = y_test[y_pre!=y_test]\n",
    "for i,(img, p) in enumerate(zip(x_test[y_pre!=y_test], predict[y_pre!=y_test])):\n",
    "    ax1=plt.subplot(2,4,i+1)\n",
    "    ax1.imshow(img)\n",
    "    #ax.set_title(\"label = %d\"%label)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([]) \n",
    "    ax2=plt.subplot(2,4,i+5)\n",
    "    color[a[i]] = 'b'\n",
    "    ax2.bar(x=['Normal','Pneumonia','Covid-19'],height=p,width=0.5,color=color)\n",
    "    #ax.set_title(\"label = %d\"%label)\n",
    "    color=['r','r','r']\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767bab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将标签二值化\n",
    "y = label_binarize(y_test, classes=[0, 1, 2])\n",
    "y_pre = predict\n",
    "# 设置种类\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], y_pre[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_pre.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "roc_auc[\"micro\"] = roc_auc_score(y, y_pre, multi_class=\"ovo\", average=\"micro\")\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    " \n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    " \n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "#roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "roc_auc[\"macro\"] = roc_auc_score(y, y_pre, multi_class=\"ovo\", average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all ROC curves\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.figure(figsize=(7, 5), dpi=1000)\n",
    "lw = 2\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "  label='micro-average ROC curve (area = {0:0.4f})'.format(roc_auc[\"micro\"]), color='deeppink', linestyle=':', linewidth=4)\n",
    " \n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "  label='macro-average ROC curve (area = {0:0.4f})'.format(roc_auc[\"macro\"]), color='navy', linestyle=':', linewidth=4)\n",
    " \n",
    "colors = cycle(['green', 'blue', 'red'])\n",
    "classes = ['Normal', 'Pneumonia', 'COVID-19']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, linestyle='-', label='ROC curve of class {0} (area = {1:0.4f})'.format(classes[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\", fontsize='x-small')\n",
    "#{'xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large'})\n",
    "plt.savefig('./model-cv/fig/ROC-fold5.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62629e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.load(path5 + \"acc.npy\")\n",
    "val_acc = np.load(path5 + \"val_acc.npy\")\n",
    "loss = np.load(path5 + \"loss.npy\")\n",
    "val_loss = np.load(path5 + \"val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea00804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use(['science', 'ieee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['ieee']):\n",
    "    fig = plt.figure(figsize=(3.5,3.5), dpi=1000)\n",
    "    # 布局与图例\n",
    "    layout = (2, 1)\n",
    "    acc_ax = plt.subplot2grid(layout, (0, 0))\n",
    "    loss_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    acc_ax.plot(acc, color='blue')\n",
    "    acc_ax.plot(val_acc)\n",
    "    acc_ax.set_title('Accuracy vs. Number of Training Epochs', fontweight=\"bold\")\n",
    "    acc_ax.set_ylabel('Accuracy', fontweight=\"bold\")\n",
    "    acc_ax.set_xlabel('Epochs', fontweight=\"bold\")\n",
    "    acc_ax.legend(['Training', 'Validation'])\n",
    "\n",
    "    loss_ax.plot(loss, color='blue')\n",
    "    loss_ax.plot(val_loss)\n",
    "    loss_ax.set_title('Loss vs. Number of Training Epochs', fontweight=\"bold\")\n",
    "    loss_ax.set_ylabel('Loss', fontweight=\"bold\")\n",
    "    loss_ax.set_xlabel('Epochs', fontweight=\"bold\")\n",
    "    loss_ax.legend(['Training', 'Validation'])\n",
    "\n",
    "    # 自动调整图例布局\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./model-cv/fig/fold5_acc+loss.png', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = [path1, path2, path3, path4, path5]\n",
    "fig = plt.figure(figsize=(10, 5.3), dpi=1000)\n",
    "sn.set(font_scale=0.6)  # for label size\n",
    "x = 230\n",
    "for path in path_list:\n",
    "    x += 1\n",
    "    df_cm = pd.read_csv(path + 'cm.csv', index_col=0)\n",
    "#     df_cm.index.name = 'Actual'\n",
    "#     df_cm.columns.name = 'Predicted'\n",
    "    ax = plt.subplot(x)\n",
    "    h_m = sn.heatmap(df_cm, cmap=\"BuPu\", annot=True, annot_kws={\"size\": 10, \"fontweight\": \"bold\"}, fmt='d', ax=ax, cbar=True)\n",
    "    h_m.set_yticklabels(h_m.get_yticklabels(), rotation=0, fontweight=\"bold\")\n",
    "    h_m.set_xticklabels(h_m.get_xticklabels(), rotation=0, fontweight=\"bold\")\n",
    "    h_m.set_title('Fold-'+ str(x-230),fontdict={'fontsize': 8, 'fontweight': \"bold\"})\n",
    "# 自动调整图例布局\n",
    "\n",
    "plt.tight_layout()     \n",
    "\n",
    "fig.savefig('./model-cv/fig/' + 'confusion_matrix.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d717404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70117855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a629a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93271352",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"newData/image.npy\")\n",
    "Y = np.load(\"newData/label.npy\")\n",
    "\n",
    "predict = model.predict([X])\n",
    "\n",
    "y = label_binarize(Y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], predict[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "roc_auc[\"macro\"] = roc_auc_score(y, predict, multi_class=\"ovo\", average=\"macro\")\n",
    "roc_auc[\"weighted\"] = roc_auc_score(y, predict, multi_class=\"ovo\", average=\"weighted\")\n",
    "\n",
    "\n",
    "y_pre = np.argmax(predict, axis=1)\n",
    "report = classification_report(Y, y_pre, output_dict=True)\n",
    "df1 = pd.DataFrame(report).transpose()\n",
    "df1['auc'] = [roc_auc[0], roc_auc[1], roc_auc[2], '', roc_auc[\"macro\"], roc_auc[\"weighted\"]]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将标签二值化\n",
    "y = label_binarize(Y, classes=[0, 1, 2])\n",
    "y_pre = predict\n",
    "# 设置种类\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], y_pre[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_pre.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "roc_auc[\"micro\"] = roc_auc_score(y, y_pre, multi_class=\"ovo\", average=\"micro\")\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    " \n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    " \n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "#roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "roc_auc[\"macro\"] = roc_auc_score(y, y_pre, multi_class=\"ovo\", average=\"macro\")\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.figure(figsize=(7, 5), dpi=1000)\n",
    "lw = 2\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "  label='micro-average ROC curve (area = {0:0.4f})'.format(roc_auc[\"micro\"]), color='deeppink', linestyle=':', linewidth=4)\n",
    " \n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "  label='macro-average ROC curve (area = {0:0.4f})'.format(roc_auc[\"macro\"]), color='navy', linestyle=':', linewidth=4)\n",
    " \n",
    "colors = cycle(['green', 'blue', 'red'])\n",
    "classes = ['Normal', 'Pneumonia', 'COVID-19']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, linestyle='-', label='ROC curve of class {0} (area = {1:0.4f})'.format(classes[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\", fontsize='x-small')\n",
    "#{'xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large'})\n",
    "plt.savefig('./model-cv/fig/ROC.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f86792",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = np.argmax(y_pre, axis=1)\n",
    "data = confusion_matrix(Y, y_pre)\n",
    "names = ['Normal', 'Pneumonia', 'COVID-19']\n",
    "df_cm = pd.DataFrame(data, columns=names, index=names)\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "fig = plt.figure(figsize=(3.5, 3), dpi=1000)\n",
    "ax = plt.subplot(222)\n",
    "sn.set(font_scale=0.4)  # for label size\n",
    "h_m = sn.heatmap(df_cm, cmap=\"BuPu\", annot=True, annot_kws={\"size\": 5, \"fontweight\": \"bold\"}, fmt='d', cbar=True)\n",
    "# \n",
    "h_m.set_yticklabels(h_m.get_yticklabels(), rotation=0, fontweight=\"bold\")\n",
    "h_m.set_xticklabels(h_m.get_xticklabels(), rotation=45, fontweight=\"bold\")\n",
    "fig.savefig('./model-cv/fig' + '/' + 'confusion_matrix2.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbaaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
