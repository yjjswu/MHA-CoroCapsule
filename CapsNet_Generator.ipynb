{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suited-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, Sequential, regularizers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from evaluation import compute_performance_measures\n",
    "from utils import *\n",
    "from layers import *\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  #按需分配显存\n",
    "#keras.backend.tensorflow_backend.set_session(tf.compat.v1.Session(config=config))\n",
    "tf.random.set_seed(111111)\n",
    "np.random.seed(111111)\n",
    "random.seed(111111)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77d6678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name() #检测tensorflow是否可以使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9fc47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13661710415211996815]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices() #列出所有的本地机器设备（CPU和GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "soviet-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsnet(inputs):\n",
    "    x = Conv2D(16, 5, 1, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, 5, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(64, 5, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(128, 5, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3, center=True, scale=True, beta_initializer=\"random_uniform\", gamma_initializer=\"random_uniform\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    \n",
    "    x = PrimaryCaps_H(32, 8, 9, 1, padding='SAME')(x)\n",
    "\n",
    "    digit_caps = DigitCaps(3, 16, 3)(x)\n",
    "\n",
    "\n",
    "    digit_caps_len = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(digit_caps)\n",
    "    model = Model(inputs=[inputs], outputs=[digit_caps, digit_caps_len], name='CapsNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optimum-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_shape):\n",
    "    inputs = Input(16*3)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "    x = tf.keras.layers.Reshape(target_shape=input_shape, name='out_generator')(x)\n",
    "    \n",
    "    return Model(inputs=[inputs], outputs=[x], name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominican-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(Layer):\n",
    "    def call(self, inputs, double_mask=None, **kwargs):\n",
    "        if type(inputs) is list:\n",
    "            if double_mask:\n",
    "                inputs, mask1, mask2 = inputs\n",
    "            else:\n",
    "                inputs, mask = inputs\n",
    "        else:  \n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            if double_mask:\n",
    "                mask1 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,0],num_classes=x.get_shape().as_list()[1])\n",
    "                mask2 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,1],num_classes=x.get_shape().as_list()[1])\n",
    "            else:\n",
    "                mask = tf.keras.backend.one_hot(indices=tf.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        if double_mask:\n",
    "            masked1 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask1, -1))\n",
    "            masked2 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask2, -1))\n",
    "            return masked1, masked2\n",
    "        else:\n",
    "            masked = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "            return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  \n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # generation step\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "christian-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, y_true, mode='train'):\n",
    "    capsnet_model = capsnet(inputs)\n",
    "    digit_caps, digit_caps_len = capsnet_model(inputs)\n",
    "    \n",
    "    # 重构\n",
    "    masked_by_y = Mask()([digit_caps, y_true])  \n",
    "    masked = Mask()(digit_caps)\n",
    "    \n",
    "    generator_model = generator([128, 128, 3])\n",
    "    x_gen_train = generator_model(masked_by_y)\n",
    "    x_gen_eval = generator_model(masked)\n",
    "    \n",
    "    if mode == 'train':   \n",
    "        return Model([inputs, y_true], [digit_caps_len, x_gen_train], name='CapsNet_Generator')\n",
    "    elif mode == 'test':\n",
    "        return Model(inputs, [digit_caps_len, x_gen_eval], name='CapsNet_Generator')\n",
    "    else:\n",
    "        raise RuntimeError('mode not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afraid-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128, 128, 3))\n",
    "y_true = Input(shape=(3,))\n",
    "\n",
    "model = create_model(inputs, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stuck-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CapsNet_Generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CapsNet (Functional)            [(None, 3, 16), (Non 6071440     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (Mask)                     (None, None)         0           CapsNet[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Generator (Functional)          (None, 128, 128, 3)  50931200    mask[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 57,002,640\n",
      "Trainable params: 57,002,160\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "model.compile(loss=[margin_loss, 'mse'], optimizer=adam, loss_weights=[1., 0.392], metrics={'CapsNet': 'accuracy'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "x_valid = np.load(\"data/x_valid.npy\")\n",
    "y_valid = np.load(\"data/y_valid.npy\")\n",
    "x_test =  np.load(\"data/x_test.npy\")\n",
    "y_test =  np.load(\"data/y_test.npy\")\n",
    "\n",
    "batch_size = 16  \n",
    "num_classes = 3\n",
    "epochs = 100\n",
    "\n",
    "#class weights to handle class imbalance\n",
    "class_weights = {0: 1-np.count_nonzero(y_train==0)/len(y_train), \n",
    "                 1: 1-np.count_nonzero(y_train==1)/len(y_train), \n",
    "                 2: 1-np.count_nonzero(y_train==2)/len(y_train)}\n",
    "\n",
    "\n",
    "# 将整型标签转为onehot\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_valid = utils.to_categorical(y_valid, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(image, label):\n",
    "    return (image, label), (label, image)\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset_train = dataset_train.map(generator, num_parallel_calls=16)\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "dataset_train = dataset_train.prefetch(-1)\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "dataset_valid = dataset_valid.map(generator, num_parallel_calls=16)\n",
    "dataset_valid = dataset_valid.batch(batch_size)\n",
    "dataset_valid = dataset_valid.prefetch(-1)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "dataset_test = dataset_test.map(generator, num_parallel_calls=16)\n",
    "dataset_test = dataset_test.batch(batch_size)\n",
    "dataset_test = dataset_test.prefetch(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.totaltime = time.time()\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.totaltime = time.time() - self.totaltime\n",
    "        \n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is selected based on the loss value on the validation set\n",
    "filepath=\"model/weights/weights-CapsNet-best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_CapsNet_loss', \n",
    "                             save_best_only=True, save_weights_only=True, verbose=1, mode='min')\n",
    "\n",
    "#learning decay rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5 \n",
    "    epochs_drop = 20  \n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "callbacks_list = [checkpoint, lrate, time_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-harbor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(dataset_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(dataset_valid), \n",
    "                    #class_weight=class_weights, \n",
    "                    shuffle=True, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback.totaltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/weights/weights-CapsNet-best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(dataset_test)\n",
    "predict = predict[0]\n",
    "y_pre = np.argmax(predict, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_test, y_pre, output_dict=True)\n",
    "df1 = pd.DataFrame(report).transpose()\n",
    "# Write it into csv format\n",
    "df1.to_csv('model/report.csv', index=True, header=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measures = compute_performance_measures(y_pre, y_test)\n",
    "pm = {'acc': perf_measures.Acc,         # 准确率\n",
    "      'recall': perf_measures.Recall,   # 召回率\n",
    "      'spe': perf_measures.Specificity, # 特异度\n",
    "      'pre': perf_measures.Precision,   # 精确度\n",
    "      'f1': perf_measures.F_measure,    # F1\n",
    "      'avgacc': perf_measures.Overall_Acc\n",
    "     }\n",
    "df2 = pd.DataFrame(pm)\n",
    "df2.to_csv('model/pm.csv', index=True, header=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = confusion_matrix(y_test, y_pre)\n",
    "names = ['normal', 'pneumonia', 'COVID-19']\n",
    "df_cm = pd.DataFrame(data, columns=names, index=names)\n",
    "df_cm.to_csv('model/cm.csv', index=True, header=True)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "layer_model = Model(inputs=model.input, outputs=model.get_layer('CapsNet').get_layer('digit_caps').output)\n",
    "#以这个model的预测值作为输出\n",
    "feature = layer_model.predict(x_test)\n",
    "\n",
    "feature_flattened = [a.flatten() for a in feature]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "# prjected 2d data\n",
    "\n",
    "feature_2d = tsne.fit_transform(feature_flattened)\n",
    "\n",
    "feature_2d_covid = feature_2d[y_test==2]\n",
    "feature_2d_normal = feature_2d[y_test==0]\n",
    "feature_2d_non = feature_2d[y_test==1]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "colors = ['mediumseagreen', 'cornflowerblue', 'darkorange']\n",
    "classes = ['Normal', 'Pneumonia', 'COVID-19']\n",
    "\n",
    "plt.scatter(feature_2d_covid[:, 0], feature_2d_covid[:, 1], c = colors[2], marker = 'o', label=classes[2])\n",
    "plt.scatter(feature_2d_normal[:, 0], feature_2d_normal[:, 1], c = colors[0], marker = 'o', label=classes[0])\n",
    "plt.scatter(feature_2d_non[:, 0], feature_2d_non[:, 1], c = colors[1], marker = 'o', label=classes[1])\n",
    "\n",
    "#plt.title('COVID-19 t-SNE')\n",
    "#plt.legend(loc=\"lower left\")\n",
    "plt.legend()\n",
    "#plt.savefig('model/MHACapsNet t-SNE.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-track",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
